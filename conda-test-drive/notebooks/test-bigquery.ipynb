{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B\"H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE: \n",
    "#    - https://cloud.google.com/bigquery/docs/reference/libraries\n",
    "#    - https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=/home/laz/app-keys/stats-learning-d392db36f6a4.json\n"
     ]
    }
   ],
   "source": [
    "%set_env GOOGLE_APPLICATION_CREDENTIALS=/home/laz/app-keys/stats-learning-d392db36f6a4.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiates a client\n",
    "bq_client = bigquery.Client(project='stats-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.client.Client at 0x7f1e350d8b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## List datasets for the clientâ€™s project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project stats-learning:\n",
      "\tds_stats\n",
      "\tpinpoint\n"
     ]
    }
   ],
   "source": [
    "datasets = list(bq_client.list_datasets())\n",
    "project = bq_client.project\n",
    "\n",
    "if datasets:\n",
    "    print('Datasets in project {}:'.format(project))\n",
    "    for dataset in datasets:  # API request(s)\n",
    "        print('\\t{}'.format(dataset.dataset_id))\n",
    "else:\n",
    "    print('{} project does not contain any datasets.'.format(project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List tables for the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = bq_client.dataset('pinpoint')\n",
    "\n",
    "tables = list(bq_client.list_tables(dataset_ref))  # API request(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<google.cloud.bigquery.table.TableListItem at 0x7f1e68358358>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e34fb8f98>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e34fb80f0>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e34fb89b0>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e34fb8e80>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e34fb8278>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e3501e5f8>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e3501e588>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e3501e518>,\n",
       " <google.cloud.bigquery.table.TableListItem at 0x7f1e3501e4e0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extract a table to Google Cloud Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.ExtractJob at 0x7f1e34fe09b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name     = 'bucket-stats'\n",
    "\n",
    "destination_uri = 'gs://{}/{}'.format(bucket_name, 'test-export.csv')\n",
    "\n",
    "# -- ------------------------------------------------------------------\n",
    "\n",
    "dataset_ref     = bq_client.dataset('pinpoint')\n",
    "\n",
    "table_ref       = dataset_ref.table('x_stg_CREATE_TEST')\n",
    "\n",
    "# -- ------------------------------------------------------------------\n",
    "\n",
    "extract_job = bq_client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uri,\n",
    "    # Location must match that of the source table.\n",
    "    location='US'\n",
    ")  \n",
    "\n",
    "extract_job.result()  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Overwrite / replace an existing table with a CSV file from Cloud Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ------------------------------------------------------------------\n",
    "table_ref = dataset_ref.table('x_stg_CREATE_TEST')\n",
    "# -- ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# -- ------------------------------------------------------------------\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job_config.skip_leading_rows = 1\n",
    "\n",
    "# The source format defaults to CSV, so the line below is optional.\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "# -- ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# -- ------------------------------------------------------------------\n",
    "load_job = bq_client.load_table_from_uri(    \n",
    "    'gs://bucket-stats/test-export.csv',\n",
    "    table_ref,\n",
    "    job_config = job_config\n",
    ")  # API request\n",
    "\n",
    "assert load_job.job_type == 'load'\n",
    "\n",
    "load_job.result()  # Waits for table load to complete.\n",
    "# -- ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# -- ------------------------------------------------------------------\n",
    "assert load_job.state == 'DONE'\n",
    "assert bq_client.get_table(table_ref).num_rows == 3\n",
    "# -- ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Writing query results to a destination table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- -----------------------------------------------------\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "# Set the destination table. \n",
    "table_ref = dataset_ref.table('x_stg_create_from_query')\n",
    "\n",
    "job_config.destination = table_ref\n",
    "\n",
    "# The write_disposition specifies the behavior when writing query results\n",
    "# to a table that already exists. With WRITE_TRUNCATE, any existing rows\n",
    "# in the table are overwritten by the query results.\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "# -- -----------------------------------------------------\n",
    "\n",
    "\n",
    "# -- -----------------------------------------------------\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_str = (\n",
    "    'SELECT   my_dates, my_int64 '\n",
    "    'FROM     `stats-learning.pinpoint.x_stg_CREATE_TEST`  '\n",
    "    'WHERE    my_int64 > 1 '\n",
    ")\n",
    "\n",
    "query_job = bq_client.query(\n",
    "    query_str,\n",
    "    # Location must match that of the dataset(s) referenced in the query and of the destination table.\n",
    "    location   = 'US',\n",
    "    job_config = job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "rows = list(query_job)  # Waits for the query to finish\n",
    "\n",
    "assert len(rows) == 2\n",
    "# -- -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pinpoint)",
   "language": "python",
   "name": "pinpoint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
